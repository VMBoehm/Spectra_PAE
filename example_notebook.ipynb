{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfeef1a9-60b7-45d5-af85-3aef8c6ef9f6",
   "metadata": {},
   "source": [
    "## Train a PAE on labeled galaxy spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d347b3dc-dd10-40fc-8e32-5dd887a39d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from spectra_pae.spectra_pae import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3daa61-2641-4547-a59b-a0633c22ff72",
   "metadata": {},
   "source": [
    "Note: To fully understand what this code is doing under the hood, you need to read the paper, look at the Spectra_PAE class and the PytorchPAE package with the Autoencoder class. All of these are well documented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f11a332-2c4c-4868-a118-2f2d277a450d",
   "metadata": {},
   "source": [
    "### set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b48d8a77-9eaf-4d6f-8c4a-eb3c9ecb2f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED               = 287505\n",
    "\n",
    "## dataset name (if you want to add a new dataset, it must be added to the the PytorchPAE package in custom_datasets.py) \n",
    "dataset_name       = 'SDSS_DR16'\n",
    "# dataset directory\n",
    "data_dir           = '/global/cscratch1/sd/vboehm/Datasets/sdss/by_model'\n",
    "# directory for saving trained models \n",
    "model_dir          = '/global/cscratch1/sd/vboehm/SDSSOutlier/fc'\n",
    "# dimensionality of the input data \n",
    "input_dim          = (1000,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad9492-a9c2-4c04-98b8-b3f0623836cd",
   "metadata": {},
   "source": [
    "### initiate the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d1e6108-34f5-4ae4-ad05-e9bc035df1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all functionalities are described in the class documentation \n",
    "SPAE = Spectra_PAE(data_dir, model_dir, dataset_name='SDSS_DR16', input_dim=input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc106dde-b433-4824-b082-8df13a8f0268",
   "metadata": {},
   "source": [
    "### Train the full model. This goes through all training steps described in the publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74cc3b9d-a4ad-41b2-8665-8599819d4636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training AE stage 1...\n",
      "epoch: 1, training loss: 4.1023e+00, validation loss: 1.9990e+00, learning rate: 1.0000e-03\n",
      "epoch: 2, training loss: 1.7914e+00, validation loss: 1.5753e+00, learning rate: 9.9000e-04\n",
      "epoch: 3, training loss: 1.6515e+00, validation loss: 1.5127e+00, learning rate: 9.8010e-04\n",
      "epoch: 4, training loss: 1.5878e+00, validation loss: 1.5267e+00, learning rate: 9.7030e-04\n",
      "epoch: 5, training loss: 1.5550e+00, validation loss: 1.6459e+00, learning rate: 9.6060e-04\n",
      "epoch: 6, training loss: 1.5387e+00, validation loss: 1.5077e+00, learning rate: 9.5099e-04\n",
      "epoch: 7, training loss: 1.5130e+00, validation loss: 1.4945e+00, learning rate: 9.4148e-04\n",
      "epoch: 8, training loss: 1.4949e+00, validation loss: 1.4704e+00, learning rate: 9.3207e-04\n",
      "epoch: 9, training loss: 1.4819e+00, validation loss: 1.4210e+00, learning rate: 9.2274e-04\n",
      "saved model to \"/global/cscratch1/sd/vboehm/SDSSOutlier/fc/AE1.ckpt\"\n",
      "epoch: 10, training loss: 1.4641e+00, validation loss: 1.4329e+00, learning rate: 9.1352e-04\n",
      "AE stage 1 training completed.\n",
      "evaluating AE stage 1 train...\n",
      "evaluating AE stage 1 valid...\n",
      "evaluating AE stage 1 test...\n",
      "training AE stage 2...\n",
      "epoch: 1, training loss: 1.2589e-01, validation loss: 8.1000e-02, learning rate: 1.0000e-03\n",
      "epoch: 2, training loss: 1.1761e-01, validation loss: 1.2884e-01, learning rate: 9.9000e-04\n",
      "epoch: 3, training loss: 1.4205e-01, validation loss: 7.0098e-02, learning rate: 9.8010e-04\n",
      "epoch: 4, training loss: 1.7147e-01, validation loss: 1.0482e-01, learning rate: 9.7030e-04\n",
      "epoch: 5, training loss: 1.4529e-01, validation loss: 3.0760e-01, learning rate: 9.6060e-04\n",
      "epoch: 6, training loss: 1.5993e-01, validation loss: 2.2024e-01, learning rate: 9.5099e-04\n",
      "saved model to \"/global/cscratch1/sd/vboehm/SDSSOutlier/fc/AE2.ckpt\"\n",
      "AE stage 2 training completed.\n",
      "evaluating AE stage 2 train...\n",
      "evaluating AE stage 2 valid...\n",
      "evaluating AE stage 2 test...\n",
      "training Normalizing Flow Stage 1...\n",
      "10 16\n",
      "After whiten logp: -8.915218353271484 -8.506792068481445\n",
      "Fit A: Time: 5.3489423828125 Wasserstein Distance: [1.2103654146194458, 1.173718810081482, 1.1289329528808594, 0.9364648461341858, 0.8505633473396301, 0.6973541975021362, 0.6017102599143982, 0.5622166991233826]\n",
      "logp: -6.715628147125244 -6.319492816925049 time: 11.086769104003906 iteration: 2 best: 2\n",
      "Fit A: Time: 1.4477041015625 Wasserstein Distance: [1.14423406124115, 1.109434962272644, 1.053797721862793, 0.9014515280723572, 0.7720255851745605, 0.6283021569252014, 0.557859480381012, 0.5271846652030945]\n",
      "logp: -4.985648155212402 -4.600808143615723 time: 7.156400918960571 iteration: 3 best: 3\n",
      "Fit A: Time: 1.4264925537109374 Wasserstein Distance: [1.1220389604568481, 1.0451576709747314, 0.971038281917572, 0.7599241733551025, 0.6826111078262329, 0.6559673547744751, 0.5544241666793823, 0.5274336934089661]\n",
      "logp: -3.6533732414245605 -3.2773051261901855 time: 7.148728370666504 iteration: 4 best: 4\n",
      "Fit A: Time: 1.41027294921875 Wasserstein Distance: [1.027145504951477, 0.9815276861190796, 0.9592542052268982, 0.8207693099975586, 0.6543321013450623, 0.5690718293190002, 0.5169869661331177, 0.34572693705558777]\n",
      "logp: -2.516773223876953 -2.1490120887756348 time: 6.844483852386475 iteration: 5 best: 5\n",
      "Fit A: Time: 1.4187091064453126 Wasserstein Distance: [1.0052704811096191, 0.9267635941505432, 0.8552914261817932, 0.819570004940033, 0.5776002407073975, 0.547795295715332, 0.5156130194664001, 0.44926685094833374]\n",
      "logp: -1.3962898254394531 -1.0358824729919434 time: 6.981751203536987 iteration: 6 best: 6\n",
      "Fit A: Time: 0.5940521850585937 Wasserstein Distance: [0.9159373641014099, 0.7928787469863892, 0.7536510229110718, 0.7433091998100281, 0.676314651966095, 0.6529215574264526, 0.5890238285064697, 0.4602826237678528]\n",
      "logp: -0.6233749389648438 -0.2682509422302246 time: 6.004529237747192 iteration: 7 best: 7\n",
      "Fit A: Time: 1.412432861328125 Wasserstein Distance: [0.9291554093360901, 0.9073871374130249, 0.7563693523406982, 0.6888509392738342, 0.5800797343254089, 0.5128580331802368, 0.4783382713794708, 0.44738397002220154]\n",
      "logp: 0.13424921035766602 0.48149728775024414 time: 6.923066854476929 iteration: 8 best: 8\n",
      "Fit A: Time: 1.411992431640625 Wasserstein Distance: [0.8672038912773132, 0.7398443818092346, 0.6930736303329468, 0.6820622086524963, 0.6549047827720642, 0.6177191138267517, 0.5085949897766113, 0.4678027033805847]\n",
      "logp: 1.1226425170898438 1.4629359245300293 time: 7.038616895675659 iteration: 9 best: 9\n",
      "Fit A: Time: 1.4290985107421874 Wasserstein Distance: [0.891880214214325, 0.7410378456115723, 0.7224581241607666, 0.7103732824325562, 0.5337215662002563, 0.5040598511695862, 0.46831461787223816, 0.4175663888454437]\n",
      "logp: 1.7182350158691406 2.05222749710083 time: 6.9519264698028564 iteration: 10 best: 10\n",
      "Fit A: Time: 1.3770771484375 Wasserstein Distance: [0.8204876184463501, 0.7451316118240356, 0.7020925283432007, 0.635647714138031, 0.5599204897880554, 0.4882839620113373, 0.47048941254615784, 0.4321118891239166]\n",
      "logp: 2.2524094581604004 2.582942008972168 time: 6.793403625488281 iteration: 11 best: 11\n",
      "Fit A: Time: 1.423295654296875 Wasserstein Distance: [0.7554724812507629, 0.7259160280227661, 0.6536082625389099, 0.6374792456626892, 0.5597710013389587, 0.5590080618858337, 0.46109241247177124, 0.433441162109375]\n",
      "logp: 2.9024548530578613 3.2268099784851074 time: 6.98261833190918 iteration: 12 best: 12\n",
      "Fit A: Time: 0.6489844970703125 Wasserstein Distance: [0.7032775282859802, 0.6613162755966187, 0.658089280128479, 0.6565015316009521, 0.5702381134033203, 0.4879514276981354, 0.47084423899650574, 0.4241400361061096]\n",
      "logp: 3.31398868560791 3.6340060234069824 time: 6.5567626953125 iteration: 13 best: 13\n",
      "Fit A: Time: 1.4130902099609375 Wasserstein Distance: [0.8135635852813721, 0.7480698823928833, 0.5266090035438538, 0.5227510333061218, 0.5158947110176086, 0.5070172548294067, 0.4914027154445648, 0.4112570583820343]\n",
      "logp: 3.8071799278259277 4.123884201049805 time: 6.916311502456665 iteration: 14 best: 14\n",
      "Fit A: Time: 1.4290989990234375 Wasserstein Distance: [0.7109895348548889, 0.6601306200027466, 0.6164530515670776, 0.5577343106269836, 0.5469096302986145, 0.5080734491348267, 0.45012807846069336, 0.44638025760650635]\n",
      "logp: 4.201499938964844 4.514747619628906 time: 7.097701549530029 iteration: 15 best: 15\n",
      "Fit A: Time: 1.442001953125 Wasserstein Distance: [0.807963490486145, 0.5863054394721985, 0.5680381655693054, 0.5363888144493103, 0.5241365432739258, 0.4951893091201782, 0.4519229531288147, 0.35955145955085754]\n",
      "logp: 4.558253765106201 4.868378639221191 time: 6.897917032241821 iteration: 16 best: 16\n",
      "Fit A: Time: 1.1774278564453124 Wasserstein Distance: [0.843600869178772, 0.6800143718719482, 0.5229071974754333, 0.48829615116119385, 0.4631202518939972, 0.46151891350746155, 0.402580201625824, 0.3378273546695709]\n",
      "logp: 4.899641990661621 5.207935333251953 time: 6.931834697723389 iteration: 17 best: 17\n",
      "Fit A: Time: 1.269771484375 Wasserstein Distance: [0.624186635017395, 0.613703727722168, 0.5965157747268677, 0.5902372598648071, 0.5317088961601257, 0.4803430140018463, 0.41763466596603394, 0.3991236984729767]\n",
      "logp: 5.219099521636963 5.523975849151611 time: 7.137073278427124 iteration: 18 best: 18\n",
      "Fit A: Time: 0.9991173095703125 Wasserstein Distance: [0.6740450859069824, 0.591036319732666, 0.5566361546516418, 0.5282803177833557, 0.5167598128318787, 0.4563849866390228, 0.4465314447879791, 0.42537739872932434]\n",
      "logp: 5.476211071014404 5.778590202331543 time: 6.434115886688232 iteration: 19 best: 19\n",
      "Fit A: Time: 1.291704345703125 Wasserstein Distance: [0.8202217221260071, 0.6558672189712524, 0.5198287963867188, 0.47460249066352844, 0.45870065689086914, 0.376535028219223, 0.37118807435035706, 0.34679773449897766]\n",
      "logp: 5.76685905456543 6.0675153732299805 time: 6.858893394470215 iteration: 20 best: 20\n",
      "Fit A: Time: 1.371881591796875 Wasserstein Distance: [0.6391278505325317, 0.5896214842796326, 0.5859354734420776, 0.5292620062828064, 0.5246872305870056, 0.4938175678253174, 0.3654804229736328, 0.3109429180622101]\n",
      "logp: 6.053127765655518 6.351217746734619 time: 6.955941438674927 iteration: 21 best: 21\n",
      "Fit A: Time: 1.5421107177734374 Wasserstein Distance: [0.7169211506843567, 0.6343261003494263, 0.571729838848114, 0.45842599868774414, 0.4069965183734894, 0.39423835277557373, 0.38696610927581787, 0.3802312910556793]\n",
      "logp: 6.287916660308838 6.583475112915039 time: 7.070678234100342 iteration: 22 best: 22\n",
      "Fit A: Time: 0.7774232177734375 Wasserstein Distance: [0.5941237211227417, 0.5562846064567566, 0.5134543776512146, 0.512875497341156, 0.5062596201896667, 0.48326319456100464, 0.44982749223709106, 0.39434605836868286]\n",
      "computing prior probabilities...\n",
      "reclassify by identifying labels with highest probability under NF1...\n",
      "classifying...\n",
      "classifying...\n",
      "classifying...\n",
      "loading trained NF2...\n"
     ]
    }
   ],
   "source": [
    "# for testing set nepochs to 10 and niter to 20\n",
    "SPAE.train_complete_model(nepochs=100, use_prior=True, retrain=True, niter=500)\n",
    "#target loss for AE stage 1 is ~1.1-1.2, stage 2 should be O(1e-4)\n",
    "\n",
    "\"\"\"\n",
    "trains and saves complete model\n",
    "--------\n",
    "nepochs: number of epochs to train for (you could add an early stopping criteria on validation loss)\n",
    "retrain: whether to retrain even if model if files exist (better to change the name under which the models are saved by chanin the prefixes)\n",
    "use_prior: whether to use a prior when evaluating the class probability\n",
    "niter: number of training steps in the normalizing flow\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21babe34-2084-4517-afc0-54f8c21aa92d",
   "metadata": {},
   "source": [
    "### get log probability of all spectra in the combined validation set under the most likely label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98c7fb2-a189-4642-80f2-8dbc89afc399",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the initial dataset is divided into training, validation and test set. However, I combine validation and test set into one dataset in the publication.\n",
    "## the data I'm sharing is actually: training set = training set, validation set = validation + test set, test set = test set. \n",
    "## You can recover the original split between validation and test set from this. \n",
    "logps = SPAE.evaluate_NF2(SPAE.NF1_data['valid'],SPAE.new_labels['valid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af2c01c-031d-4b3e-8d8d-ddea855318eb",
   "metadata": {},
   "source": [
    "### evaluate the rank (in terms of percentile) of a single spectrum with respect to a reference sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd60b27d-f30e-4b7e-af56-7c7af98f9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that I'm not using the training set as a reference sample here. This is to avoid biases from potential overfitting. \n",
    "# In the training I do not penalize overfitting as long as the validation loss keeps improving. Early stopping is based on the validation loss not improving, not the training loss!\n",
    "rank = SPAE.evaluate_logp_percentile(SPAE.NF1_data['valid'],SPAE.labels['valid'], SPAE.NF1_data['valid'][0:1],SPAE.labels['valid'][0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9513fe6d-a3b8-4afe-8ff2-896687ab870b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
